{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wow-glimmer/stylegan2_scripts/blob/master/public_StyleGAN2_Colab_Train.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnExkcWXj705",
        "colab_type": "text"
      },
      "source": [
        "# stylegan2 - ppp/1\n",
        "unfinished, paths may be diffrent between cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3olnCjv-R_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# P100 - Great\n",
        "!nvidia-smi\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJazuNYurryY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RESUME TRAINING QUICKLY, edit this\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#USE this if you already have a stylegan2 folder in google drive\n",
        "%cd /content/drive/My\\ Drive/stylegan2-colab-256/stylegan2\n",
        "!git pull\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "!ls datasets/256_test\n",
        "!cp -vr datasets/256_test /content/datasets\n",
        "\n",
        "!python run_training.py --num-gpus=1 --data-dir=/content/ --image_snapshot_ticks 1 --config=config-f --dataset=datasets --mirror-augment=true --metrics=None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcDHP4h-11Ii",
        "colab_type": "text"
      },
      "source": [
        "##Mounting Google Drive\n",
        "So I’m actually gonna install my entire repo directly into Google Drive. This will make the setup a little easier, but its a little strange I admit.\n",
        "\n",
        "First, connect your Drive to Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aadrbMyR2F00",
        "colab_type": "text"
      },
      "source": [
        "## Install the repo\n",
        "**Only do this for the first time ever setting this up!**\n",
        "\n",
        "If this is your first time ever running this notebook, you’ll want to install my fork of StyleGAN2 to your Drive account. Make sure you have ample space on your Drive (I’d say at least 50GB). This will install the repo and add some dependecies (like transferring from FFHQ the first time).\n",
        "\n",
        "Every time after your first use of this notebook you’ll want to skip this cell and run the cell after this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoTNQ3Gyr0ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SKIP this if you already have a stylegan2 folder in your google drive\n",
        "%cd /content/drive/My\\ Drive/\n",
        "!mkdir stylegan2-colab-256 # <------------------------ rename this for multiple installations\n",
        "%cd stylegan2-colab-256/\n",
        "!git clone https://github.com/dvschultz/stylegan2\n",
        "%cd stylegan2\n",
        "!mkdir pkl\n",
        "%cd pkl\n",
        "!gdown --id 1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF #inception: https://drive.google.com/open?id=1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF\n",
        "%cd ../\n",
        "!mkdir results\n",
        "!mkdir results/00001-pretrained\n",
        "%cd results/00001-pretrained\n",
        "# change these for custom pretrained model\n",
        "!gdown --id 1UlDmJVLLnBD9SnLSMXeiZRO6g-OMQCA_ # faces (1024 x 1024 image size)\n",
        "!mv stylegan2-ffhq-config-f.pkl network-snapshot-10000.pkl\n",
        "\n",
        "# donwload horses (3d) pretrained model (256 x 256 image size)\n",
        "#!wget http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-horse-config-f.pkl\n",
        "#!mv stylegan2-horse-config-f.pkl network-snapshot-10000.pkl\n",
        "\n",
        "\n",
        "%cd ../../\n",
        "%mkdir datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN2K68CE27py",
        "colab_type": "text"
      },
      "source": [
        "## Picking up from a previous session\n",
        "If you already have the StyleGAN2 repo installed in Drive skip the above cell and run the following. This will make sure you have the latest version in case I make updates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8WgjhRFsFJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#USE this if you already have a stylegan2 folder in google drive\n",
        "%cd /content/drive/My\\ Drive/stylegan2-colab-256/stylegan2\n",
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSbEY2pT3TOb",
        "colab_type": "text"
      },
      "source": [
        "##Make sure Tensorflow 1.15 is set\n",
        "Colab now defaults to Tensorflow 2. Make sure you run this cell to reset it to TF1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMdpKY1XODz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1pIBZGzZxSA",
        "colab_type": "text"
      },
      "source": [
        "# Process dataset\n",
        "StyleGAN requires you to convert your standard jpg or png images into a new format (.tfrecords). \n",
        "\n",
        "I’ve seen some recommendations to run this command every time you restart your Colab machine. I think if you ahve a small-ish dataset (< 2000 images) that’s probably unnecessary.\n",
        "\n",
        "I recommend you upload your dataset to Google Drive and copy its path from the Drive folder in Colab and paste its path in the below cell.\n",
        "\n",
        "After the `create_from_images` argument you need to pass in two paths. The first path is where the .tfrecords files should be output (just edit the last part to have a unique name). The second path is to the directory of your images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract \"merged_dataset.tar\" (on gdrive) to /content/ ( on VM )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tar -C \"/content/\" -xvf \"/content/drive/My Drive/sgan/_stylegan2/merged_dataset.tar\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate tfrecords ( !python dataset_tool.py create_from_images dest source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python dataset_tool.py create_from_images datasets/merged_dataset /content/256_glim_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You might also want to copy tfrecords to grive and back to save time with !cp -vr command"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----------\n",
        "# Training here\n",
        "\n",
        "##Training\n",
        "Note: this will require you to restart your Colab machine every 8–16 hours.\n",
        "This library is set up to automatically find your latest .pkl file so it should keep re-training and making progress.\n",
        "\n",
        "##Training Options\n",
        "`--dataset`\n",
        "This should be the name you used in the first path when converting your dataset.\n",
        "\n",
        "`--mirror-augment`\n",
        "Using this option loads some images at random mirrored horizontally (left-to-right). This might help if you have a very small dataset.\n",
        "\n",
        "`--metrics`\n",
        "use `--metrics=None` (not required, takes long time)\n",
        "If you must use metrics, you have a few options. `fid50k`, the default, uses Frechet Inception Distance score. It’s what was used in StyleGAN1 and what most people know. It’s fine for images of animals and things, but it’s not great. `ppl_wend` is what StyleGAN2 prefers and claims to be more accurate. There are a bunch of other options but I’d recommend you stick with those. Note that both of these take 30–45minutes to run every time it runs so that cuts into your training time in Colab.\n",
        "\n",
        "`--network_snapshot_ticks 1`  <---- save each tick, default: 4 (one save = 300mb on gdrive)\n",
        "\n",
        "\n",
        "Once running, your training files will show up in the results folder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LQ1oXtQM9iD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python run_training.py --num-gpus=1 --data-dir=/content --config=config-f --network_snapshot_ticks 1 --dataset=merged_dataset --mirror-augment=true --metrics=None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F9vCDt9LRtXl"
      },
      "source": [
        "------------\n",
        "# Generate images\n",
        "The following command will generate 55 sample images from the model.\n",
        "\n",
        "##Options\n",
        "`--network`\n",
        "\n",
        "Make sure the `--network` argument points to your .pkl file. (My preferred method is to right click on the file in the Files pane to your left and choose `Copy Path`, then paste that into the argument after the `=` sign).\n",
        "\n",
        "`--seeds`\n",
        "\n",
        "This allows you to choose random seeds from the model. Remember that our input to StyleGAN is a 512-dimensional array. These seeds will generate those 512 values. Each seed will generate a different, random array. The same seed value will also always generate the same random array, so we can later use it for other purposes like interpolation.\n",
        "\n",
        "`--truncation-psi`\n",
        "\n",
        "Truncation is a special argument of StyleGAN. Essentially values that are closer to 0 will be more real than numbers further away from 0. I generally recommend a value between `0.5` and `1.0`. `0.5` will give you pretty \"realistic\" results, while `1.0` is likely to give you \"weirder\" results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnt6zpQm06LI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install opensimplex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3MhXEAMOMXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python run_generator.py generate-images --network=results/00011-stylegan2-my-custom-dataset-1gpu-config-f/network-snapshot-010195.pkl --seeds=3875451-3876000 --truncation-psi=0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMiqkA3IReZB",
        "colab_type": "text"
      },
      "source": [
        "Let’s zip the generated files and download them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp8O01O3PlFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r generated-0.7.zip /content/stylegan2/results/00000-generate-images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTwJjmCrlfAc",
        "colab_type": "text"
      },
      "source": [
        "# Interpolation (latent-walk)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ2rYIC4TdaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python run_generator.py generate-latent-walk --network=results/00011-stylegan2-my-custom-dataset-1gpu-config-f/network-snapshot-010195.pkl --seeds=3,11,17,25,3 --frames 200 --truncation-psi=0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dceBSxTsmW1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert to video \n",
        "!ffmpeg -r 24 -i results/00014-generate-latent-walk/step%05d.png -vcodec libx264 -pix_fmt yuv420p latent-walk-v2.mp4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7A7jRRGmzhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#delete\n",
        "rm -r /content/drive/My Drive/stylegan2-colab-test/stylegan2/results/00002-stylegan2-birdaus-1gpu-config-f"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "public StyleGAN2-Colab-Train.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}